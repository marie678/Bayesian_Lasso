{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pymc as pm\n",
    "import arviz as az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We simulated n = 20 data set to fit models and n = 200 data set\n",
    "to compare prediction errors of proposed models with eight predictors. We let\n",
    "$β = (3, 1.5, 0, 0, 2, 0, 0, 0)′$ and $σ = 3$. The pairwise correlation between $x_i$ and $x_j$\n",
    "was set to be $corr(i, j) = 0.5^{|i−j|}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_train = 20  # Number of training samples\n",
    "n_test = 200  # Number of testing samples\n",
    "p = 8         # Number of predictors\n",
    "beta1 = np.array([3, 1.5, 0, 0, 2, 0, 0, 0])  # True regression coefficients\n",
    "sigma = 3     # Standard deviation of noise\n",
    "corr_decay = 0.5\n",
    "\n",
    "# Create covariance matrix based on corr(i, j) = 0.5^|i-j|\n",
    "cov_matrix = np.fromfunction(\n",
    "    lambda i, j: corr_decay ** np.abs(i - j),\n",
    "    (p, p),\n",
    "    dtype=int\n",
    ")\n",
    "\n",
    "# Generate training predictors and noise\n",
    "X_train = np.random.multivariate_normal(mean=np.zeros(p), cov=cov_matrix, size=n_train)\n",
    "epsilon_train = np.random.normal(loc=0, scale=1, size=n_train)\n",
    "\n",
    "# Generate training response (y)\n",
    "y_train = X_train @ beta1 + sigma * epsilon_train\n",
    "\n",
    "# Generate testing predictors and noise\n",
    "X_test = np.random.multivariate_normal(mean=np.zeros(p), cov=cov_matrix, size=n_test)\n",
    "epsilon_test = np.random.normal(loc=0, scale=1, size=n_test)\n",
    "\n",
    "# Generate testing response (y)\n",
    "y_test = X_test @ beta1 + sigma * epsilon_test\n",
    "\n",
    "# Output data\n",
    "print(\"Training data shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing data shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate empirical correlation matrix\n",
    "corr_matrix = np.corrcoef(X_train, rowvar=False)\n",
    "\n",
    "# Calculate theoretical correlation matrix\n",
    "p = X_train.shape[1]\n",
    "theoretical_corr_matrix = np.fromfunction(\n",
    "    lambda i, j: corr_decay ** np.abs(i - j),\n",
    "    (p, p),\n",
    "    dtype=int\n",
    ")\n",
    "\n",
    "# Plot both side by side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", ax=axes[0], cbar=False)\n",
    "axes[0].set_title(\"Empirical Correlation Matrix (X_train)\")\n",
    "sns.heatmap(theoretical_corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", ax=axes[1], cbar=False)\n",
    "axes[1].set_title(\"Theoretical Correlation Matrix (0.5^|i-j|)\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple linear regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "print(lr.intercept_)\n",
    "print(lr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Frequentist Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid for alpha (regularization parameter)\n",
    "param_grid = {'alpha': [0.01, 0.1, 0.3, 0.5, 0.8, 0.9, 1, 1.1, 2, 5, 10]}\n",
    "\n",
    "# Perform Grid Search with Cross-Validation\n",
    "grid = GridSearchCV(Lasso(fit_intercept=True), param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Retrieve the best alpha and corresponding model\n",
    "best_alpha = grid.best_params_['alpha']\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "# Predictions using the best model\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "mse_train_freq = mean_squared_error(y_train, y_pred_train)\n",
    "mse_test_freq = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "# Print the results\n",
    "print(\"Frequentist Lasso Results with Hyperparameter Tuning:\")\n",
    "print(f\"Best alpha: {best_alpha}\")\n",
    "print(f\"Train MSE: {mse_train_freq:.3f}\")\n",
    "print(f\"Test MSE: {mse_test_freq:.3f}\")\n",
    "print(\"Best Coefficients:\", best_model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, column in enumerate(range(X_train.shape[1])):\n",
    "    print(f\"Predictor {i+1} correlation with y_train: {np.corrcoef(X_train[:, column], y_train)[0, 1]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "elastic_net = ElasticNet(alpha=1, l1_ratio=0.7)\n",
    "elastic_net.fit(X_train, y_train)\n",
    "print(\"Elastic Net Coefficients:\", elastic_net.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bayesian Lasso\n",
    "(Using NUTS and not Gibbs sampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With mean estimators :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1  # Shape parameter for Gamma prior\n",
    "b = 0.1  # Scale parameter for Gamma prior\n",
    "\n",
    "with pm.Model() as bayesian_lasso:\n",
    "    # Prior for regularization parameter lambda\n",
    "    lambda_param = pm.Gamma(\"lambda\", alpha=a, beta=b)\n",
    "    \n",
    "    # Priors for the regression coefficients\n",
    "    tau = pm.Exponential(\"tau\", lambda_param, shape=X_train.shape[1])\n",
    "    beta = pm.Normal(\"beta\", mu=0, sigma=tau, shape=X_train.shape[1])\n",
    "    \n",
    "    # Prior for intercept\n",
    "    intercept = pm.Normal(\"intercept\", mu=0, sigma=10)\n",
    "    \n",
    "    # Likelihood (data model)\n",
    "    sigma = pm.HalfNormal(\"sigma\", sigma=1)\n",
    "    mu = intercept + pm.math.dot(X_train, beta)\n",
    "    likelihood = pm.Normal(\"y\", mu=mu, sigma=sigma, observed=y_train)\n",
    "\n",
    "    # Inference\n",
    "    trace = pm.sample(1000, tune=1000, target_accept=0.9,  return_inferencedata=True, progressbar=True)\n",
    "\n",
    "# Posterior summaries\n",
    "pm.plot_posterior(trace, var_names=[\"beta\", \"intercept\"], hdi_prob=0.95)\n",
    "\n",
    "summary = az.summary(trace, var_names=[\"beta\", \"intercept\"], hdi_prob=0.95)\n",
    "display(summary)\n",
    "\n",
    "# Retrieve the posterior means for the coefficients\n",
    "beta_post_mean = trace.posterior[\"beta\"].mean(axis=(0,1))\n",
    "intercept_post_mean = trace.posterior[\"intercept\"].mean()\n",
    "print(\"Bayesian Lasso Results:\")\n",
    "print(\"Posterior Means for Coefficients:\", beta_post_mean)\n",
    "print(\"Posterior Mean for Intercept:\", intercept_post_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posterior Predictions\n",
    "with bayesian_lasso:\n",
    "    posterior_predictive = pm.sample_posterior_predictive(trace)\n",
    "\n",
    "posterior_predictive_data = posterior_predictive['posterior_predictive']\n",
    "# print(\"Available keys inside posterior_predictive:\", list(posterior_predictive_data.keys()))\n",
    "\n",
    "# Extract the predictions\n",
    "y_pred_samples = posterior_predictive_data['y'].values\n",
    "# Compute posterior mean of y for each observation (across all chains and draws)\n",
    "y_pred_mean = y_pred_samples.mean(axis=(0, 1))  # Averaging over chains (axis=0) and draws (axis=1)\n",
    "# Extract observed y values\n",
    "y_obs = posterior_predictive['observed_data']['y'].values\n",
    "\n",
    "# Compute the Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_obs, y_pred_mean)\n",
    "print(f\"MSE: {mse:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for the test dataset\n",
    "with bayesian_lasso:\n",
    "    # Extract posterior samples of beta and intercept\n",
    "    beta_samples = trace.posterior[\"beta\"].stack(samples=(\"chain\", \"draw\")).values\n",
    "    intercept_samples = trace.posterior[\"intercept\"].stack(samples=(\"chain\", \"draw\")).values\n",
    "\n",
    "# Compute predicted means for X_test\n",
    "y_pred_test_samples = np.dot(X_test, beta_samples) + intercept_samples\n",
    "# Compute posterior predictive mean (average over all samples)\n",
    "y_pred_test_mean = y_pred_test_samples.mean(axis=1)  # Averaging over all posterior samples\n",
    "\n",
    "# Compute the Mean Squared Error (MSE) for the test set\n",
    "mse_test = mean_squared_error(y_test, y_pred_test_mean)\n",
    "print(f\"MSE on Test Set: {mse_test:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With mode estimators :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1  # Shape parameter for Gamma prior\n",
    "b = 0.1  # Scale parameter for Gamma prior\n",
    "\n",
    "with pm.Model() as bayesian_lasso:\n",
    "    # Prior for regularization parameter lambda\n",
    "    lambda_param = pm.Gamma(\"lambda\", alpha=a, beta=b)\n",
    "    \n",
    "    # Priors for the regression coefficients\n",
    "    tau = pm.Exponential(\"tau\", lambda_param, shape=X_train.shape[1])\n",
    "    beta = pm.Normal(\"beta\", mu=0, sigma=tau, shape=X_train.shape[1])\n",
    "    \n",
    "    # Prior for intercept\n",
    "    intercept = pm.Normal(\"intercept\", mu=0, sigma=10)\n",
    "    \n",
    "    # Likelihood (data model)\n",
    "    sigma = pm.HalfNormal(\"sigma\", sigma=1)\n",
    "    mu = intercept + pm.math.dot(X_train, beta)\n",
    "    likelihood = pm.Normal(\"y\", mu=mu, sigma=sigma, observed=y_train)\n",
    "\n",
    "    # Find the posterior mode\n",
    "    map_estimate = pm.find_MAP()\n",
    "\n",
    "# Extract posterior mode for beta and intercept\n",
    "beta_post_mode = map_estimate[\"beta\"]\n",
    "intercept_post_mode = map_estimate[\"intercept\"]\n",
    "\n",
    "# Display results\n",
    "print(\"Bayesian Lasso Results:\")\n",
    "print(\"Posterior Mode for Coefficients:\", beta_post_mode)\n",
    "print(\"Posterior Mode for Intercept:\", intercept_post_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True coefficients\n",
    "print(\"True beta: \", beta1)\n",
    "\n",
    "# Frequentist Lasso Coefficients\n",
    "print('\\n----- FREQUENTIST LASSO -----')\n",
    "# lasso = LassoCV(cv=5).fit(X_train, y_train)\n",
    "print(\"\\nFrequentist Lasso Coefficients:\", best_model.coef_)\n",
    "print(f\"\\nMSE on Train Set: {mse_train_freq:.3f}\")\n",
    "print(f\"\\nMSE on Test Set: {mse_test_freq:.3f}\")\n",
    "\n",
    "# Bayesian Lasso Posterior Means\n",
    "print('\\n----- BAYESIAN LASSO -----')\n",
    "# beta_post_mean = trace.posterior[\"beta\"].mean(axis=(0, 1))\n",
    "print(\"\\nBayesian Lasso Posterior Means:\", beta_post_mean)\n",
    "print(f\"\\nMSE on Train Set: {mse:.3f}\")\n",
    "print(f\"\\nMSE on Test Set: {mse_test:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1 with n= 200 in the training dataset \n",
    "We want to assess if for larger samples in the training set, the MSE performance on the test set would the less volatile and lower for the Bayesian Lasso. \\\n",
    "In this case, we simply change $n\\_train = 20$ to $n\\_train = 200$ in Example 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_train = 200  # Number of training samples\n",
    "n_test = 200  # Number of testing samples\n",
    "p = 8         # Number of predictors\n",
    "beta1 = np.array([3, 1.5, 0, 0, 2, 0, 0, 0])  # True regression coefficients\n",
    "sigma = 3     # Standard deviation of noise\n",
    "corr_decay = 0.5\n",
    "\n",
    "# Create covariance matrix based on corr(i, j) = 0.5^|i-j|\n",
    "cov_matrix = np.fromfunction(\n",
    "    lambda i, j: corr_decay ** np.abs(i - j),\n",
    "    (p, p),\n",
    "    dtype=int\n",
    ")\n",
    "\n",
    "# Generate training predictors and noise\n",
    "X_train = np.random.multivariate_normal(mean=np.zeros(p), cov=cov_matrix, size=n_train)\n",
    "epsilon_train = np.random.normal(loc=0, scale=1, size=n_train)\n",
    "\n",
    "# Generate training response (y)\n",
    "y_train = X_train @ beta1 + sigma * epsilon_train\n",
    "\n",
    "# Generate testing predictors and noise\n",
    "X_test = np.random.multivariate_normal(mean=np.zeros(p), cov=cov_matrix, size=n_test)\n",
    "epsilon_test = np.random.normal(loc=0, scale=1, size=n_test)\n",
    "\n",
    "# Generate testing response (y)\n",
    "y_test = X_test @ beta1 + sigma * epsilon_test\n",
    "\n",
    "# Output data\n",
    "print(\"Training data shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing data shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate empirical correlation matrix\n",
    "corr_matrix = np.corrcoef(X_train, rowvar=False)\n",
    "\n",
    "# Calculate theoretical correlation matrix\n",
    "p = X_train.shape[1]\n",
    "theoretical_corr_matrix = np.fromfunction(\n",
    "    lambda i, j: corr_decay ** np.abs(i - j),\n",
    "    (p, p),\n",
    "    dtype=int\n",
    ")\n",
    "\n",
    "# Plot both side by side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", ax=axes[0], cbar=False)\n",
    "axes[0].set_title(\"Empirical Correlation Matrix (X_train)\")\n",
    "sns.heatmap(theoretical_corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", ax=axes[1], cbar=False)\n",
    "axes[1].set_title(\"Theoretical Correlation Matrix (0.5^|i-j|)\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple linear regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "print(lr.intercept_)\n",
    "print(lr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Frequentist Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid for alpha (regularization parameter)\n",
    "param_grid = {'alpha': [0.01, 0.1, 0.3, 0.5, 0.8, 0.9, 1, 1.1, 2, 5, 10]}\n",
    "\n",
    "# Perform Grid Search with Cross-Validation\n",
    "grid = GridSearchCV(Lasso(fit_intercept=True), param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Retrieve the best alpha and corresponding model\n",
    "best_alpha = grid.best_params_['alpha']\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "# Predictions using the best model\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "mse_train_freq = mean_squared_error(y_train, y_pred_train)\n",
    "mse_test_freq = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "# Print the results\n",
    "print(\"Frequentist Lasso Results with Hyperparameter Tuning:\")\n",
    "print(f\"Best alpha: {best_alpha}\")\n",
    "print(f\"Train MSE: {mse_train_freq:.3f}\")\n",
    "print(f\"Test MSE: {mse_test_freq:.3f}\")\n",
    "print(\"Best Coefficients:\", best_model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bayesian Lasso\n",
    "(Using NUTS and not Gibbs sampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With mean estimators :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1  # Shape parameter for Gamma prior\n",
    "b = 0.1  # Scale parameter for Gamma prior\n",
    "\n",
    "with pm.Model() as bayesian_lasso:\n",
    "    # Prior for regularization parameter lambda\n",
    "    lambda_param = pm.Gamma(\"lambda\", alpha=a, beta=b)\n",
    "    \n",
    "    # Priors for the regression coefficients\n",
    "    tau = pm.Exponential(\"tau\", lambda_param, shape=X_train.shape[1])\n",
    "    beta = pm.Normal(\"beta\", mu=0, sigma=tau, shape=X_train.shape[1])\n",
    "    \n",
    "    # Prior for intercept\n",
    "    intercept = pm.Normal(\"intercept\", mu=0, sigma=10)\n",
    "    \n",
    "    # Likelihood (data model)\n",
    "    sigma = pm.HalfNormal(\"sigma\", sigma=1)\n",
    "    mu = intercept + pm.math.dot(X_train, beta)\n",
    "    likelihood = pm.Normal(\"y\", mu=mu, sigma=sigma, observed=y_train)\n",
    "\n",
    "    # Inference\n",
    "    trace = pm.sample(1000, tune=1000, target_accept=0.9,  return_inferencedata=True, progressbar=True)\n",
    "\n",
    "# Posterior summaries\n",
    "pm.plot_posterior(trace, var_names=[\"beta\", \"intercept\"], hdi_prob=0.95)\n",
    "\n",
    "summary = az.summary(trace, var_names=[\"beta\", \"intercept\"], hdi_prob=0.95)\n",
    "display(summary)\n",
    "\n",
    "# Retrieve the posterior means for the coefficients\n",
    "beta_post_mean = trace.posterior[\"beta\"].mean(axis=(0,1))\n",
    "intercept_post_mean = trace.posterior[\"intercept\"].mean()\n",
    "print(\"Bayesian Lasso Results:\")\n",
    "print(\"Posterior Means for Coefficients:\", beta_post_mean)\n",
    "print(\"Posterior Mean for Intercept:\", intercept_post_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posterior Predictions\n",
    "with bayesian_lasso:\n",
    "    posterior_predictive = pm.sample_posterior_predictive(trace)\n",
    "\n",
    "posterior_predictive_data = posterior_predictive['posterior_predictive']\n",
    "# print(\"Available keys inside posterior_predictive:\", list(posterior_predictive_data.keys()))\n",
    "\n",
    "# Extract the predictions\n",
    "y_pred_samples = posterior_predictive_data['y'].values\n",
    "# Compute posterior mean of y for each observation (across all chains and draws)\n",
    "y_pred_mean = y_pred_samples.mean(axis=(0, 1))  # Averaging over chains (axis=0) and draws (axis=1)\n",
    "# Extract observed y values\n",
    "y_obs = posterior_predictive['observed_data']['y'].values\n",
    "\n",
    "# Compute the Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_obs, y_pred_mean)\n",
    "print(f\"MSE: {mse:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for the test dataset\n",
    "with bayesian_lasso:\n",
    "    # Extract posterior samples of beta and intercept\n",
    "    beta_samples = trace.posterior[\"beta\"].stack(samples=(\"chain\", \"draw\")).values\n",
    "    intercept_samples = trace.posterior[\"intercept\"].stack(samples=(\"chain\", \"draw\")).values\n",
    "\n",
    "# Compute predicted means for X_test\n",
    "y_pred_test_samples = np.dot(X_test, beta_samples) + intercept_samples\n",
    "# Compute posterior predictive mean (average over all samples)\n",
    "y_pred_test_mean = y_pred_test_samples.mean(axis=1)  # Averaging over all posterior samples\n",
    "\n",
    "# Compute the Mean Squared Error (MSE) for the test set\n",
    "mse_test = mean_squared_error(y_test, y_pred_test_mean)\n",
    "print(f\"MSE on Test Set: {mse_test:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With mode estimators :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1  # Shape parameter for Gamma prior\n",
    "b = 0.1  # Scale parameter for Gamma prior\n",
    "\n",
    "with pm.Model() as bayesian_lasso:\n",
    "    # Prior for regularization parameter lambda\n",
    "    lambda_param = pm.Gamma(\"lambda\", alpha=a, beta=b)\n",
    "    \n",
    "    # Priors for the regression coefficients\n",
    "    tau = pm.Exponential(\"tau\", lambda_param, shape=X_train.shape[1])\n",
    "    beta = pm.Normal(\"beta\", mu=0, sigma=tau, shape=X_train.shape[1])\n",
    "    \n",
    "    # Prior for intercept\n",
    "    intercept = pm.Normal(\"intercept\", mu=0, sigma=10)\n",
    "    \n",
    "    # Likelihood (data model)\n",
    "    sigma = pm.HalfNormal(\"sigma\", sigma=1)\n",
    "    mu = intercept + pm.math.dot(X_train, beta)\n",
    "    likelihood = pm.Normal(\"y\", mu=mu, sigma=sigma, observed=y_train)\n",
    "\n",
    "    # Find the posterior mode\n",
    "    map_estimate = pm.find_MAP()\n",
    "\n",
    "# Extract posterior mode for beta and intercept\n",
    "beta_post_mode = map_estimate[\"beta\"]\n",
    "intercept_post_mode = map_estimate[\"intercept\"]\n",
    "\n",
    "# Display results\n",
    "print(\"Bayesian Lasso Results:\")\n",
    "print(\"Posterior Mode for Coefficients:\", beta_post_mode)\n",
    "print(\"Posterior Mode for Intercept:\", intercept_post_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True coefficients\n",
    "print(\"True beta: \", beta1)\n",
    "\n",
    "# Frequentist Lasso Coefficients\n",
    "print('\\n----- FREQUENTIST LASSO -----')\n",
    "# lasso = LassoCV(cv=5).fit(X_train, y_train)\n",
    "print(\"\\nFrequentist Lasso Coefficients:\", best_model.coef_)\n",
    "print(f\"\\nMSE on Train Set: {mse_train_freq:.3f}\")\n",
    "print(f\"\\nMSE on Test Set: {mse_test_freq:.3f}\")\n",
    "\n",
    "# Bayesian Lasso Posterior Means\n",
    "print('\\n----- BAYESIAN LASSO -----')\n",
    "# beta_post_mean = trace.posterior[\"beta\"].mean(axis=(0, 1))\n",
    "print(\"\\nBayesian Lasso Posterior Means:\", beta_post_mean)\n",
    "print(f\"\\nMSE on Train Set: {mse:.3f}\")\n",
    "print(f\"\\nMSE on Test Set: {mse_test:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 2 is the same as Example 1, except that $β_j = 0.65$ for all $j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_train = 20  # Number of training samples\n",
    "n_test = 200  # Number of testing samples\n",
    "p = 8         # Number of predictors\n",
    "beta2 = np.array([0.65]*8)  # True regression coefficients\n",
    "sigma = 3     # Standard deviation of noise\n",
    "corr_decay = 0.5\n",
    "\n",
    "# Create covariance matrix based on corr(i, j) = 0.5^|i-j|\n",
    "cov_matrix = np.fromfunction(\n",
    "    lambda i, j: corr_decay ** np.abs(i - j),\n",
    "    (p, p),\n",
    "    dtype=int\n",
    ")\n",
    "\n",
    "# Generate training predictors and noise\n",
    "X_train = np.random.multivariate_normal(mean=np.zeros(p), cov=cov_matrix, size=n_train)\n",
    "epsilon_train = np.random.normal(loc=0, scale=1, size=n_train)\n",
    "\n",
    "# Generate training response (y)\n",
    "y_train = X_train @ beta2 + sigma * epsilon_train\n",
    "\n",
    "# Generate testing predictors and noise\n",
    "X_test = np.random.multivariate_normal(mean=np.zeros(p), cov=cov_matrix, size=n_test)\n",
    "epsilon_test = np.random.normal(loc=0, scale=1, size=n_test)\n",
    "\n",
    "# Generate testing response (y)\n",
    "y_test = X_test @ beta2 + sigma * epsilon_test\n",
    "\n",
    "# Output data\n",
    "print(\"Training data shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing data shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate empirical correlation matrix\n",
    "corr_matrix = np.corrcoef(X_train, rowvar=False)\n",
    "\n",
    "# Calculate theoretical correlation matrix\n",
    "p = X_train.shape[1]\n",
    "theoretical_corr_matrix = np.fromfunction(\n",
    "    lambda i, j: corr_decay ** np.abs(i - j),\n",
    "    (p, p),\n",
    "    dtype=int\n",
    ")\n",
    "\n",
    "# Plot both side by side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", ax=axes[0], cbar=False)\n",
    "axes[0].set_title(\"Empirical Correlation Matrix (X_train)\")\n",
    "sns.heatmap(theoretical_corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", ax=axes[1], cbar=False)\n",
    "axes[1].set_title(\"Theoretical Correlation Matrix (0.5^|i-j|)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple linear regression model\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "print(lr.intercept_)\n",
    "print(lr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Frequentist Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid for alpha (regularization parameter)\n",
    "param_grid = {'alpha': [0.01, 0.1, 0.3, 0.5, 0.9, 1, 3, 5, 10]}\n",
    "\n",
    "# Perform Grid Search with Cross-Validation\n",
    "grid = GridSearchCV(Lasso(fit_intercept=True), param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Retrieve the best alpha and corresponding model\n",
    "best_alpha = grid.best_params_['alpha']\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "# Predictions using the best model\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "mse_train_freq = mean_squared_error(y_train, y_pred_train)\n",
    "mse_test_freq = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "# Print the results\n",
    "print(\"Frequentist Lasso Results with Hyperparameter Tuning:\")\n",
    "print(f\"Best alpha: {best_alpha}\")\n",
    "print(f\"Train MSE: {mse_train_freq:.3f}\")\n",
    "print(f\"Test MSE: {mse_test_freq:.3f}\")\n",
    "print(\"Best Coefficients:\", best_model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test of an ElasticNet : also bad\n",
    "elastic_net = ElasticNet(alpha=1, l1_ratio=0.7)\n",
    "elastic_net.fit(X_train, y_train)\n",
    "print(\"Elastic Net Coefficients:\", elastic_net.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bayesian Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With mean estimators :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1  # Shape parameter for Gamma prior\n",
    "b = 0.1  # Scale parameter for Gamma prior\n",
    "\n",
    "with pm.Model() as bayesian_lasso:\n",
    "    # Prior for regularization parameter lambda\n",
    "    lambda_param = pm.Gamma(\"lambda\", alpha=a, beta=b)\n",
    "    \n",
    "    # Priors for the regression coefficients\n",
    "    tau = pm.Exponential(\"tau\", lambda_param, shape=X_train.shape[1])\n",
    "    beta = pm.Normal(\"beta\", mu=0, sigma=tau, shape=X_train.shape[1])\n",
    "    \n",
    "    # Prior for intercept\n",
    "    intercept = pm.Normal(\"intercept\", mu=0, sigma=10)\n",
    "    \n",
    "    # Likelihood (data model)\n",
    "    sigma = pm.HalfNormal(\"sigma\", sigma=1)\n",
    "    mu = intercept + pm.math.dot(X_train, beta)\n",
    "    likelihood = pm.Normal(\"y\", mu=mu, sigma=sigma, observed=y_train)\n",
    "\n",
    "    # Inference\n",
    "    trace = pm.sample(1000, tune=1000, target_accept=0.9,  return_inferencedata=True, progressbar=True)\n",
    "\n",
    "# Posterior summaries\n",
    "pm.plot_posterior(trace, var_names=[\"beta\", \"intercept\"], hdi_prob=0.95)\n",
    "\n",
    "summary = az.summary(trace, var_names=[\"beta\", \"intercept\"], hdi_prob=0.95)\n",
    "display(summary)\n",
    "\n",
    "# Retrieve the posterior means for the coefficients\n",
    "beta_post_mean = trace.posterior[\"beta\"].mean(axis=(0,1))\n",
    "intercept_post_mean = trace.posterior[\"intercept\"].mean()\n",
    "print(\"Bayesian Lasso Results:\")\n",
    "print(\"Posterior Means for Coefficients:\", beta_post_mean)\n",
    "print(\"Posterior Mean for Intercept:\", intercept_post_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posterior Predictions\n",
    "with bayesian_lasso:\n",
    "    posterior_predictive = pm.sample_posterior_predictive(trace)\n",
    "\n",
    "posterior_predictive_data = posterior_predictive['posterior_predictive']\n",
    "# print(\"Available keys inside posterior_predictive:\", list(posterior_predictive_data.keys()))\n",
    "\n",
    "# Extract the predictions\n",
    "y_pred_samples = posterior_predictive_data['y'].values\n",
    "# Compute posterior mean of y for each observation (across all chains and draws)\n",
    "y_pred_mean = y_pred_samples.mean(axis=(0, 1))  # Averaging over chains (axis=0) and draws (axis=1)\n",
    "# Extract observed y values\n",
    "y_obs = posterior_predictive['observed_data']['y'].values\n",
    "\n",
    "# Compute the Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_obs, y_pred_mean)\n",
    "print(f\"MSE: {mse:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for the test dataset\n",
    "with bayesian_lasso:\n",
    "    # Extract posterior samples of beta and intercept\n",
    "    beta_samples = trace.posterior[\"beta\"].stack(samples=(\"chain\", \"draw\")).values\n",
    "    intercept_samples = trace.posterior[\"intercept\"].stack(samples=(\"chain\", \"draw\")).values\n",
    "\n",
    "# Compute predicted means for X_test\n",
    "y_pred_test_samples = np.dot(X_test, beta_samples) + intercept_samples\n",
    "# Compute posterior predictive mean (average over all samples)\n",
    "y_pred_test_mean = y_pred_test_samples.mean(axis=1)  # Averaging over all posterior samples\n",
    "\n",
    "# Compute the Mean Squared Error (MSE) for the test set\n",
    "mse_test = mean_squared_error(y_test, y_pred_test_mean)\n",
    "print(f\"MSE on Test Set: {mse_test:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With mode estimators :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1  # Shape parameter for Gamma prior\n",
    "b = 0.1  # Scale parameter for Gamma prior\n",
    "\n",
    "with pm.Model() as bayesian_lasso:\n",
    "    # Prior for regularization parameter lambda\n",
    "    lambda_param = pm.Gamma(\"lambda\", alpha=a, beta=b)\n",
    "    \n",
    "    # Priors for the regression coefficients\n",
    "    tau = pm.Exponential(\"tau\", lambda_param, shape=X_train.shape[1])\n",
    "    beta = pm.Normal(\"beta\", mu=0, sigma=tau, shape=X_train.shape[1])\n",
    "    \n",
    "    # Prior for intercept\n",
    "    intercept = pm.Normal(\"intercept\", mu=0, sigma=10)\n",
    "    \n",
    "    # Likelihood (data model)\n",
    "    sigma = pm.HalfNormal(\"sigma\", sigma=1)\n",
    "    mu = intercept + pm.math.dot(X_train, beta)\n",
    "    likelihood = pm.Normal(\"y\", mu=mu, sigma=sigma, observed=y_train)\n",
    "\n",
    "    # Find the posterior mode\n",
    "    map_estimate = pm.find_MAP()\n",
    "\n",
    "# Extract posterior mode for beta and intercept\n",
    "beta_post_mode = map_estimate[\"beta\"]\n",
    "intercept_post_mode = map_estimate[\"intercept\"]\n",
    "\n",
    "# Display results\n",
    "print(\"Bayesian Lasso Results:\")\n",
    "print(\"Posterior Mode for Coefficients:\", beta_post_mode)\n",
    "print(\"Posterior Mode for Intercept:\", intercept_post_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True coefficients\n",
    "print(\"True beta: \", beta2)\n",
    "\n",
    "# Frequentist Lasso Coefficients\n",
    "print('\\n----- FREQUENTIST LASSO -----')\n",
    "lasso = LassoCV(cv=5).fit(X_train, y_train)\n",
    "print(\"\\nFrequentist Lasso Coefficients:\", best_model.coef_)\n",
    "print(f\"MSE on Train Set: {mse_train_freq:.3f}\")\n",
    "print(f\"MSE on Test Set: {mse_test_freq:.3f}\")\n",
    "\n",
    "# Bayesian Lasso Posterior Means\n",
    "print('\\n----- BAYESIAN LASSO -----')\n",
    "# beta_post_mean = trace.posterior[\"beta\"].mean(axis=(0, 1))\n",
    "print(\"\\nBayesian Lasso Posterior Means:\", beta_post_mean)\n",
    "print(f\"MSE on Train Set: {mse:.3f}\")\n",
    "print(f\"MSE on Test Set: {mse_test:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 3 aims to test a scenario in which the number of regressors is higher than the number of observations. Here we have $p=50$ predictors and $n=30$ observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_train = 30 # Number of training samples\n",
    "n_test = 30  # Number of testing samples\n",
    "p = 50       # Number of predictors\n",
    "beta3 = np.random.randn(50)\n",
    "\n",
    "# Create covariance matrix based on corr(i, j) = 0.5^|i-j|\n",
    "cov_matrix = np.fromfunction(\n",
    "    lambda i, j: corr_decay ** np.abs(i - j),\n",
    "    (p, p),\n",
    "    dtype=int\n",
    ")\n",
    "\n",
    "# Generate training predictors and noise\n",
    "X_train = np.random.multivariate_normal(mean=np.zeros(p), cov=cov_matrix, size=n_train)\n",
    "epsilon_train = np.random.normal(loc=0, scale=1, size=n_train)\n",
    "\n",
    "# Generate training response (y)\n",
    "y_train = X_train @ beta3 + sigma * epsilon_train\n",
    "\n",
    "# Generate testing predictors and noise\n",
    "X_test = np.random.multivariate_normal(mean=np.zeros(p), cov=cov_matrix, size=n_test)\n",
    "epsilon_test = np.random.normal(loc=0, scale=1, size=n_test)\n",
    "\n",
    "# Generate testing response (y)\n",
    "y_test = X_test @ beta3 + sigma * epsilon_test\n",
    "\n",
    "# Output data\n",
    "print(\"Training data shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing data shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate empirical correlation matrix\n",
    "# corr_matrix = np.corrcoef(X_train, rowvar=False)\n",
    "\n",
    "# # Calculate theoretical correlation matrix\n",
    "# p = X_train.shape[1]\n",
    "# theoretical_corr_matrix = np.fromfunction(\n",
    "#     lambda i, j: corr_decay ** np.abs(i - j),\n",
    "#     (p, p),\n",
    "#     dtype=int\n",
    "# )\n",
    "\n",
    "# # Plot both side by side\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "# sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", ax=axes[0], cbar=False)\n",
    "# axes[0].set_title(\"Empirical Correlation Matrix (X_train)\")\n",
    "# sns.heatmap(theoretical_corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", ax=axes[1], cbar=False)\n",
    "# axes[1].set_title(\"Theoretical Correlation Matrix (0.5^|i-j|)\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple linear regression model\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "print(lr.intercept_)\n",
    "print(lr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Frequentist Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid for alpha (regularization parameter)\n",
    "param_grid = {'alpha': [0.01, 0.1, 0.3, 0.5, 0.9, 1, 3, 5, 10]}\n",
    "\n",
    "# Perform Grid Search with Cross-Validation\n",
    "grid = GridSearchCV(Lasso(fit_intercept=True), param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Retrieve the best alpha and corresponding model\n",
    "best_alpha = grid.best_params_['alpha']\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "# Predictions using the best model\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "mse_train_freq = mean_squared_error(y_train, y_pred_train)\n",
    "mse_test_freq = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "# Print the results\n",
    "print(\"Frequentist Lasso Results with Hyperparameter Tuning:\")\n",
    "print(f\"Best alpha: {best_alpha}\")\n",
    "print(f\"Train MSE: {mse_train_freq:.3f}\")\n",
    "print(f\"Test MSE: {mse_test_freq:.3f}\")\n",
    "print(\"Best Coefficients:\", best_model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bayesian Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With mean estimators :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1  # Shape parameter for Gamma prior\n",
    "b = 0.1  # Scale parameter for Gamma prior\n",
    "\n",
    "with pm.Model() as bayesian_lasso:\n",
    "    # Prior for regularization parameter lambda\n",
    "    lambda_param = pm.Gamma(\"lambda\", alpha=a, beta=b)\n",
    "    \n",
    "    # Priors for the regression coefficients\n",
    "    tau = pm.Exponential(\"tau\", lambda_param, shape=X_train.shape[1])\n",
    "    beta = pm.Normal(\"beta\", mu=0, sigma=tau, shape=X_train.shape[1])\n",
    "    \n",
    "    # Prior for intercept\n",
    "    intercept = pm.Normal(\"intercept\", mu=0, sigma=10)\n",
    "    \n",
    "    # Likelihood (data model)\n",
    "    sigma = pm.HalfNormal(\"sigma\", sigma=1)\n",
    "    mu = intercept + pm.math.dot(X_train, beta)\n",
    "    likelihood = pm.Normal(\"y\", mu=mu, sigma=sigma, observed=y_train)\n",
    "\n",
    "    # Inference\n",
    "    trace = pm.sample(1000, tune=1000, target_accept=0.9,  return_inferencedata=True, progressbar=True)\n",
    "\n",
    "# Posterior summaries\n",
    "pm.plot_posterior(trace, var_names=[\"beta\", \"intercept\"], hdi_prob=0.95)\n",
    "\n",
    "summary = az.summary(trace, var_names=[\"beta\", \"intercept\"], hdi_prob=0.95)\n",
    "display(summary)\n",
    "\n",
    "# Retrieve the posterior means for the coefficients\n",
    "beta_post_mean = trace.posterior[\"beta\"].mean(axis=(0,1))\n",
    "intercept_post_mean = trace.posterior[\"intercept\"].mean()\n",
    "print(\"Bayesian Lasso Results:\")\n",
    "print(\"Posterior Means for Coefficients:\", beta_post_mean)\n",
    "print(\"Posterior Mean for Intercept:\", intercept_post_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posterior Predictions\n",
    "with bayesian_lasso:\n",
    "    posterior_predictive = pm.sample_posterior_predictive(trace)\n",
    "\n",
    "posterior_predictive_data = posterior_predictive['posterior_predictive']\n",
    "# print(\"Available keys inside posterior_predictive:\", list(posterior_predictive_data.keys()))\n",
    "\n",
    "# Extract the predictions\n",
    "y_pred_samples = posterior_predictive_data['y'].values\n",
    "# Compute posterior mean of y for each observation (across all chains and draws)\n",
    "y_pred_mean = y_pred_samples.mean(axis=(0, 1))  # Averaging over chains (axis=0) and draws (axis=1)\n",
    "# Extract observed y values\n",
    "y_obs = posterior_predictive['observed_data']['y'].values\n",
    "\n",
    "# Compute the Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_obs, y_pred_mean)\n",
    "print(f\"MSE: {mse:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for the test dataset\n",
    "with bayesian_lasso:\n",
    "    # Extract posterior samples of beta and intercept\n",
    "    beta_samples = trace.posterior[\"beta\"].stack(samples=(\"chain\", \"draw\")).values\n",
    "    intercept_samples = trace.posterior[\"intercept\"].stack(samples=(\"chain\", \"draw\")).values\n",
    "\n",
    "# Compute predicted means for X_test\n",
    "y_pred_test_samples = np.dot(X_test, beta_samples) + intercept_samples\n",
    "# Compute posterior predictive mean (average over all samples)\n",
    "y_pred_test_mean = y_pred_test_samples.mean(axis=1)  # Averaging over all posterior samples\n",
    "\n",
    "# Compute the Mean Squared Error (MSE) for the test set\n",
    "mse_test = mean_squared_error(y_test, y_pred_test_mean)\n",
    "print(f\"MSE on Test Set: {mse_test:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With mode estimators :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1  # Shape parameter for Gamma prior\n",
    "b = 0.1  # Scale parameter for Gamma prior\n",
    "\n",
    "with pm.Model() as bayesian_lasso:\n",
    "    # Prior for regularization parameter lambda\n",
    "    lambda_param = pm.Gamma(\"lambda\", alpha=a, beta=b)\n",
    "    \n",
    "    # Priors for the regression coefficients\n",
    "    tau = pm.Exponential(\"tau\", lambda_param, shape=X_train.shape[1])\n",
    "    beta = pm.Normal(\"beta\", mu=0, sigma=tau, shape=X_train.shape[1])\n",
    "    \n",
    "    # Prior for intercept\n",
    "    intercept = pm.Normal(\"intercept\", mu=0, sigma=10)\n",
    "    \n",
    "    # Likelihood (data model)\n",
    "    sigma = pm.HalfNormal(\"sigma\", sigma=1)\n",
    "    mu = intercept + pm.math.dot(X_train, beta)\n",
    "    likelihood = pm.Normal(\"y\", mu=mu, sigma=sigma, observed=y_train)\n",
    "\n",
    "    # Find the posterior mode\n",
    "    map_estimate = pm.find_MAP()\n",
    "\n",
    "# Extract posterior mode for beta and intercept\n",
    "beta_post_mode = map_estimate[\"beta\"]\n",
    "intercept_post_mode = map_estimate[\"intercept\"]\n",
    "\n",
    "# Display results\n",
    "print(\"Bayesian Lasso Results:\")\n",
    "print(\"Posterior Mode for Coefficients:\", beta_post_mode)\n",
    "print(\"Posterior Mode for Intercept:\", intercept_post_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True coefficients\n",
    "print(\"True beta: \", beta3)\n",
    "\n",
    "# Frequentist Lasso Coefficients\n",
    "print('\\n----- FREQUENTIST LASSO -----')\n",
    "# lasso = LassoCV(cv=5).fit(X_train, y_train)\n",
    "print(\"\\nFrequentist Lasso Coefficients:\", best_model.coef_)\n",
    "print(f\"MSE on Train Set: {mse_train_freq:.3f}\")\n",
    "print(f\"MSE on Test Set: {mse_test_freq:.3f}\")\n",
    "\n",
    "# Bayesian Lasso Posterior Means\n",
    "print('\\n----- BAYESIAN LASSO -----')\n",
    "# beta_post_mean = trace.posterior[\"beta\"].mean(axis=(0, 1))\n",
    "print(\"\\nBayesian Lasso Posterior Means:\", beta_post_mean)\n",
    "print(f\"MSE on Train Set: {mse:.3f}\")\n",
    "print(f\"MSE on Test Set: {mse_test:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvSB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
